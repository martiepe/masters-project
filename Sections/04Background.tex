
\parencite{michelot_langevin_2019}


This thesis is motivated by the results presented in \parencite{michelot_langevin_2019}. In the article, a model for animal movement based on the Langevin process is presented, and it is shown how this model can be used to estimate the utilization distribution of an animal. A problem which arises when the time between observations is large and, is which is discussed by \parencite{michelot_langevin_2019}, is that as the time between observations increases, there is an increasing bias in the parameter estimates. In this section, the model used by \parencite{michelot_langevin_2019} is presented and some of the results of the article are reproduced.



\section{The Langevin Process}
The langevin process is a form of diffusion process described in section~\ref{sec: diffusion processes}, and takes the form

\begin{equation}
    d\textbf{X}_t = \frac{1}{2} \nabla log(\pi(\textbf{X}_t))dt + d\textbf{B}_t, \ \textbf{X}_0 = \textbf{x}_0
    \label{eq:Langevin equation}
\end{equation}


$\pi$ is referred to as the utilization distribution, and the drift term $\nabla log(\pi(\textbf{X}_t))$ steers the particle $X_t$ to areas of $\pi$ with a grater value. In an animal setting, this can be interpreted as the tendency of an animal to be attracted to certain areas over others.

\

\cite{dalalyan_theoretical_2017} states that under the conditions that $\pi$ is convex and has a Lipschitz continous gradient, the diffusion equation has a unique solution, which is a continuous time markov process with $\pi$ as the stationary distribution of $X_t$. This means that the time an animal spends in an area over the long term is determined by the utilization distribution, and we can write that

\begin{equation}
    P(\textbf{}{X}_t \in A ) = \int_A \pi(z)dz
\end{equation}


To make use of the Langevin movement model in practice, there needs to be a parameter to control the speed of the process. This is because, although two animals might have the same utilization distribution, the speed at which they travel may be different. In the Langevin process \eqref{eq:Langevin equation} the speed of a particle is determined by the utilization distribution, so two particles with the same distribution. In reality, two animals can have the same utilization distribution, but still have different speeds. \cite{roberts_optimal_1998} adds a speed parameter $\gamma^2$, to the Langevin process, which can change the speed of diffusion. The resulting process can be expressed by the equation

\begin{equation}
    d\textbf{X}_t = \frac{\gamma^2}{2} \nabla log(\pi(\textbf{X}_t))dt + \gamma d\textbf{B}_t, \ \textbf{X}_0 = \textbf{x}_0
    \label{eq:Langevin with speed}
\end{equation}


If the solution to the original Langevin process \eqref{eq:Langevin equation} is $X^*_t$ and the solution to the Langevin process \eqref{eq:Langevin with speed} with speed $\gamma^2$ is $\textbf{X}_t$, then their relationship can be expressed as $\textbf{X}_t = \textbf{X}^*_{\gamma^2 t}$. This means that the parameter scales the time of the process, making it go faster or slower.


\section{Resource Selection Functions}

Covariates can be included in the model by specifying the utilization distribution. For this we can use a Resource Selection function (RSF). An RSF is a function that expresses the probability of animal utilising a resource over all other resources in the area being studied. In this thesis I will be using an RSF of the form


\begin{equation}
    \pi(x|\beta) = \frac{exp(\sum_{i=1}^n\beta_i c_i(x))}{\int_\Omega exp(\sum_{i=1}^n\beta_i c_i(z))dz}
    \label{eq: resource selection function}
\end{equation}

$\Omega$ is the area of study, $C_i(x)$ are the spatial covariates. These can represent geographical or environmental factors that are distributed in space, and that we want to study. $\beta_i$ are the coefficients which scale the spatial covariates. by using the RSF as the utilization distribution of \eqref{eq:Langevin with speed}, we can find how the various covariates affect the animal movement, and what covariates are attractive. the slope term of \eqref{eq:Langevin with speed} then becomes

\begin{equation}
    \nabla log(\pi(x|\beta)) = \nabla log(\frac{exp(\sum_{i=1}^n\beta_i c_i(x))}{\int_\Omega exp(\sum_{i=1}^n\beta_i c_i(z))dz}) =\sum_{i=1}^n \beta_i \nabla c_i(x)
\end{equation}



environmental covariates are usually not expressed as analytical functions, as is assumed for the Langevin model and the Euler approximation of it. Most often they are stored as point data on a grid. To find the value of the covariates at points outside the grid we therefore have to interpolate from the grid. We can find values for the gradient of the covariates using the method described in subsection~\ref{subsec: gradient estimation}


\section{Likelihood Approximation of Langevin Process}
\label{sec: Likelihood Approximation of Langevin Process}
If we observe positions of the animal at locations $\textbf{x}_i$, at the times $t_i$, we can express the likelihood of the parameters $\theta$ given these jumps using a transition function $q_\Delta(\textbf{x} | \textbf{x}_t, \theta)$, where $\Delta$ is the change in time between states, and $\textbf{x}_t$ is the previous state. Because of the Markov property of the solution of the Langevin diffusion equation, we can express the entire likelihood of the animal movement as

\begin{equation}
    L(\theta | \textbf{x}) = \prod_{i=0}^{n-1} q_{\Delta_i}(\textbf{x}_{i+1} | \textbf{x}_i, \theta)
    \label{eq: Langevin likelihood}
\end{equation}

There is however a problem with this approach. For the Langevin diffusion, there is no closed form expression for $q_\Delta$\cite{gloaguen_stochastic_2018}. Instead of using the exact likelihood, pseudo likelihood methods can be used instead. One of the most used methods for approximating SDE however, is the Euler-Maruyama method described in \ref{subsec: Euler-Maruyama}. The Langevin process transition will then be approximated as

$$
    \textbf{X}_{i+1} = \textbf{X}_i + \frac{\gamma^2 \Delta_i}{2}\nabla log(\pi(\textbf{X}_i)) + \sqrt{\Delta_i}\gamma \epsilon_i
$$

where $\epsilon_i$ are standard gaussian distributions. Using this approximation, we get the transition densities $q_{\Delta_i}(\textbf{x}_{i+1} | \textbf{x}_i, \theta) = \mathcal{N}(\textbf{x}_i + \frac{\gamma^2 \Delta_i}{2}\nabla log(\pi(\textbf{x}_i)), \Delta \gamma^2 I_{2*2})$, and we get the likelihood approximation

$$L(\theta | \textbf{x}) = \prod_{i=0}^{n-1} \mathcal{N}(\textbf{x}_i + \frac{\gamma^2 \Delta_i}{2}\nabla log(\pi(\textbf{x}_i)), \Delta \gamma^2 I_{2*2})$$

%\cite{iacus_simulation_2008}.






\section{Estimating Parameters}
\label{sec: estimating parameters}
we can use the Langevin process transition approximation from subsection~\ref{sec: Likelihood Approximation of Langevin Process} to estimate the parameters used in the model. If we let $Y_i = (X_{i+1} - X_i)/\sqrt{\Delta_i}$ be the increments of the observed Langevin process, we get that $Y_i = \frac{\gamma^2}{2}\nabla log(\pi(x_i)) + \gamma \epsilon_i$. In the case that we are using a resource selection function with $j$ covariates, we can write that $\nabla log(\pi(x_i)) = \sum_{k = 1}^j \beta_k \nabla c_k(x_i)$, so we get

$$
    Y_i = \frac{\gamma^2 \sqrt{\Delta_i}}{2}\sum_{k = 1}^j \beta_k \nabla c_k(x_i) + \gamma \epsilon_i
$$

Let $Y_i = (Y_{i,1}, Y_{i,2})$ be a two dimmensional process with $\epsilon_i =(\epsilon_{i,1}, \epsilon_{i,2})$, and let

$$
    \mathbf{Y} = \begin{pmatrix}
        Y_{0,1} \\
        \vdots \\
        Y_{n-1,1}\\
        Y_{0,2}\\
        \vdots\\
        Y_{n-1,2}
    \end{pmatrix} , \    
    \mathbf{D} = \frac{1}{2} 
    \begin{pmatrix}
        \frac{\partial c_1(x_0)}{\partial z_1} & \dots & \frac{\partial c_j(x_n)}{\partial z_1} \\
        \vdots & & \vdots \\
        \frac{\partial c_1(x_n)}{\partial z_1} & \dots & \frac{\partial c_j(x_n)}{\partial z_1} \\
        \frac{\partial c_1(x_0)}{\partial z_2} & \dots & \frac{\partial c_j(x_n)}{\partial z_2} \\
        \vdots & & \vdots \\
        \frac{\partial c_1(x_n)}{\partial z_2} & \dots & \frac{\partial c_j(x_n)}{\partial z_2}
    \end{pmatrix} , \
    \mathbf{E} =\begin{pmatrix}
        \epsilon_{0,1} \\
        \vdots \\
        \epsilon_{n-1,1}\\
        \epsilon_{0,2}\\
        \vdots\\
        \epsilon_{n-1,2}
    \end{pmatrix}
$$


We can then write  that $\mathbf{Y} = \mathbf{Z} \pmb{\nu} + \mathbf{E}$, where $\mathbf{Z} = \mathbf{T}_\Delta D$ and $\mathbf{T}_\Delta$ is the $2n\times 2n$ matrix with diagonal elements $\sqrt{\Delta_i}$ for $i=1, \dots, n$ and $\sqrt{\Delta_{i-n}}$ for $i=n+1,\dots 2n$. Now the problem of finding estimates for $\pmb{\nu} = \gamma^2 \pmb{\beta}$ is that of solving a linear regression problem, so we get

$$
\pmb{\hat{\nu}} = (\mathbf{Z}^T\mathbf{Z})^{-1}\mathbf{Z}^T \mathbf{Y}
$$

Estimates for the speed parameter $\gamma^2$ and $\pmb{\beta}$ can be found by using
$$
\hat{\gamma}^2 = \frac{1}{2n-j} \lVert \mathbf{Y} - \mathbf{\hat{Y}} \rVert^2_2, \ 
\pmb{\hat{\beta}} = \frac{\pmb{\hat{\nu}}}{\hat{\gamma}^2}
\label{eq: michelot estimates}
$$



\section{Assessment of the Model}

\subsection{Accuracy of the Approximation}
To demonstrate the accuracy of the Euler approximation at various step intervals, \cite{michelot_langevin_2019} uses the Metropolis adjusted Langevin algorithm (MALA) \cite{roberts_exponential_1996}. This algorithm uses the Euler-Maruyama method as a propoasal in the metropolis hastings algorithm, and then uses the utilization distribution as the target distribution. This ensures that the stationary distribution of the Euler-Maruyama method really is the utilization distribution. The Euler-Maruyama method only approximates the Langevin process when the time intervals are small, so we should expect the acceptance rate of MALA to be small when the time inetrvals are large and close to one when the time intervals are small. Because of this we can use the MALA acceptance rate to judge at which time resolution the Euler-Maruyama method becomes a good approximation of the Langevin process. The following graph is reproduced from \cite{michelot_langevin_2019}, and shows how the acceptance rate declines as the step interval increases.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Images/example1/MALArates.pdf}
    \caption[example 1 covariates]{acceptence rate for the metropolis adjusted langevin algorithm for various values of increments of the euler approximation}
    \label{fig:MALA}
\end{figure}


Figure~\ref{fig:MALA} shows that for a time interval of $\Delta_t =0.01$ the MALA acceptance rate is close to 1. This would indicate that at this resolution, the Euler-Maruyama method is a good approximation of the Langevin process. As the time interval increases in size though, the Euler-Maruyama method becomes a worse approximation of the Langevin process.

-say what speed parameter was used

\subsection{Underestimation of Parameters}

Since the Euler-Maruyama method is a good approximation for the Langevin process at small time increments, we can use it to simulate from the Langevin process. In this subsection I replicate a simulation study performed by \parencite{michelot_langevin_2019}. In it tracks are simulated from the Langevin process using two covariates simulated by Matérn Gaussian random fields, and one covariate which is the square of the euclidean distance to the origin. The last of these covariates ensures that the Langevin process tracks don't exit the study area. Simulating covariates from a Matérn field is memory and time intensive. because of this, I instead use perlin noise simulated using the R package "ambient" with frequency parameter 0.05 and scaled by 3. The two covariates simulated using perlin noise are shown in figure~\ref{fig:covariate plots}. In addition the figure displays the utilization distribution found using the formula for a the resource selection function \eqref{eq: resource selection function} with all three covariates.


\begin{figure}[H]% 
    \centering
    \subfloat[\centering Langevin process simulations]{{\includegraphics[width=.45\linewidth]{Images/ch3/covariate 1 plot.pdf} }}%
    \qquad
    \subfloat[\centering Langevin process simulations]{{\includegraphics[width=.45\linewidth]{Images/ch3/covariate 2 plot.pdf} }}%
    \qquad
    \subfloat[\centering Langevin process simulations]{{\includegraphics[width=.45\linewidth]{Images/ch3/UD plot.pdf} }}%    
    \caption{(a) and (b) showplots of covariates simulated by perlin noise. (c) shows the utilization distribution of these covariates combined with the euclidean norm covariate}%
    \label{fig:covariate plots}%
\end{figure}


The code for generating figure\ref{fig:covariate plots} can be found in the github repository in the file "covariate plot.R". The figure shows that the covariates generated by the perlin noise contains multiple peaks and valleys, which makes it a good example for testing the method.

The third graph shows the combined utilization distribution. The thrid covariate ensures that the simulated tracks do not stray to far from the center of the map, where the slope of the utilization distribution is not defined. It also simulates how one might think an animal might stay around its home range. 

Now that we have a utilization distribution, we can use the Euler-Maruyama method to simulate tracks from the Langevin model and see how the estimated values of the parameters used compares to their actual values for different time increments between observations. To do this, 100 tracks were simulated using the Euler-Maruyama method with resolution 0.01. The tracks were then thinned by to give resolutions $0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1$ between observations, and then shortened so that they contained 5000 observations each, giving 100 tracks for each of the resolutions. The parameters $\gamma^2$ and $\beta$ were then estimated using \eqref{eq: michelot estimates}. The resulting estimates are displayed as box-plots in figure~\ref{fig:EM_thin_boxplot}


\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Images/ch3/varying dt EM boxplot.pdf}
    \caption[example 1 covariates]{Boxplots of estimated parameters for tracks with 5000 observations and varying observation intervals. The red line indicates the actual value of the parameter.}
    \label{fig:EM_thin_boxplot}
\end{figure}


The code for generating this figure can be found in the GitHub repository under the name "varying thin EM boxplot". Figure~\ref{fig:EM_thin_boxplot} shows that there is a n increasing bias in the estimates of $\beta$ as the time increments between the observations increases. Figure~\ref{fig:MALA} shows that for larger time increments, the Euler-Maruyama method is no longer a good approximation for the Langevin process likelihood, this explains why the estimates are not unbiased. \parencite{michelot_langevin_2019} explains the bias by the fact that when $\Delta_t$ is large, a lot of the movement i accordance with the utilization distribution is lost, making it appear flatter than it actually is. A track might follow the slope of the UD well, but when the intermediate states are removed that information disappears. This flattening could be an explanation for why the approximation gives estimates that are closer to zero than the true values of the parameters. Another observation is that the variance of the estimates decreases as the size of the time increments increases. \parencite{michelot_langevin_2019} explains this by the fact that for the larger increments, the observations are more spaced out, meaning that they explore more of the map. When more of the covariate range is explored, the variance of the coefficient estimates is reduced. The same bias is also observed in the $\gamma^2$ estimates. The under-estimation here might be because the distance traveled seems smaller when we have a coarser resolutions, since some of the movement is removed. Unlike what is observed for $\beta$, the variance of the estimates of $\gamma^2$ increase as the time increments increase.

